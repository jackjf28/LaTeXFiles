
\documentclass[10pt,landscape]{article}
\usepackage{graphicx}
\usepackage{amssymb,amsmath,amsthm,amsfonts}
\usepackage{multicol,multirow}
\usepackage{calc}
\usepackage{ifthen}
\usepackage{titlesec}
\usepackage[landscape]{geometry}
\usepackage[colorlinks=true,citecolor=blue,linkcolor=blue]{hyperref}
\usepackage{titlesec}


\ifthenelse{\lengthtest { \paperwidth = 11in}}
    { \geometry{top=-0in,left=.1in,right=.1in,bottom=0.1in} }
	{\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
	}
\pagestyle{empty}
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {0.1ex}%-1ex plus -.5ex minus -.2ex}%
                                {0.1ex}%0.5ex plus .2ex}%x
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {0.1ex}%-1explus -.5ex minus -.2ex}%
                                {0.1ex}%$.5ex plus .2ex}%
                                {\normalfont\footnotesize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\scriptsize\bfseries}}
                                
\makeatother
\setcounter{secnumdepth}{0}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.0ex}
\setlength{\topskip}{0pt}
\setlength{\topsep}{0pt}
\setlength{\partopsep}{0pt}
% -----------------------------------------------------------------------

%\title{A \LaTeX{} CS540 Final Study Guide, Spring 2018 - Jack Farrell}

\begin{document}

\raggedright
\footnotesize

\begin{center}
%     \Large{\textbf{A \LaTeX{} CS540 Final Study Guide, Spring 2018} - Jack Farrell} 
\end{center}
\begin{multicols}{3}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\section{**Constraint Satisfaction} 
Constraint Satisfaction Problems (CSPs) : 

\textbf{-state} is defined by \textbf{variables} $X_i$ with \textbf{values} from \textbf{domain} $D_i$

\textbf{-goal test} is a set of \textbf{constraints} specifying allowable cominations of values for subsets of variables

%Problem formulation in terms of variables, domains and constraints, constaint graph, DFS, backtracting w/ consistency checking, most constrained var heuristic, most constraining var heuristic, most constraining variable heuristic, least constraining value heuristic, min-conflicts heuristic, min-conflicts algo, forward checking algo, arc consistency algo (AC-3), combining search with CSP inference

\subsection{*Problem formulation in terms of variables}

\textbf{Map-Coloring Example:} 

Variables: WA, NT, Q, NSW, V, SA, T

Domains: $D_i$ = {red,green,blue}

Constraints: adjacent regions must have different colors

\textbf{Solutions} are \textbf{complete}(i.e., all vars are assigned values) and \textbf{consistent}(i.e., doesn't violate any constraints) assignments

\subsection{*Domains and constraints}
\textbf{Varieties of CSPs:}

\textbf{Discrete variables}

finite domains: n variables, domain size $d \to{O(d^n)}$ e.g., Boolean CSPs, Boolean satisfiability

infinite domains: integers, strings, etc e.g., job scheduling, variables are start/end times for each job

\textbf{Continuous Variables}

linear constraints solvable in polynomial time by linear programming

\textbf{Constraint Types}

\textbf{-Unary} constraints involve a single variable (e.g.,  $SA \ne green$)

\textbf{-Binary} constraints involve pairs of variables (e.g, $SA \ne WA$)

\textbf{-Higher-order} constraints involve 3 or more variables (e.g., cryptarithmetic column constraints)

\subsection{*Constraint Graph}
\textbf{-Binary CSP:} each constraint relates \textbf{two} variables

\textbf{-Constraint graph:} nodes are \textbf{variables}, arcs are \textbf{constraints}

\subsection{*DFS}

-Variable assignments are \textbf{commutative}, i.e., WA=R then NT=G same as NT=G then WA=R

\textbf{-Generate-and-test strategy}: Generate candidate soln, then test if it satisfies all constraints. Makes DFS look very stupid.

\subsection{*BackTracking(DFS) w/ Consistency Check}
\setlength\partopsep{-\topsep}
\addtolength\partopsep{-\parskip}
\addtolength\partopsep{0em}
\textbf{-Improved DFS!} Goes down one var at a time, at deadend, backs up to last var whose val can change w/o  violating constraints, and changes it

-If you backed up to the root and tried all values, there is no soln

-Complete Algo, will find soln if it exists

-Don't generate a successor that creates an inconsistency with any \emph{existing} assignment, i.e., perform \textbf{consistency checking} when node is generated.

-Successor function assigns a value to an unassignment variable that does \textbf{not} conflict with all current assignments 

\quad Deadend if no legal assignments(No successors)
\linespread{0}
\begin{verbatim}
Algorithm
Start with empty state
while not all vars in state assigned a value do
  Pick a variable(randomly or w/ heur)
  if it has a value that doesn't violate any constraints
    then Assign that value
  else
    go back to prev var and assign it another val
\end{verbatim}
%\textbf{Most Constrained Var Heur}
%-Choose variable with the fewest legal moves(most constraining variable)
 %-Called \textbf{minimum remaining values (MRV)} heuristic.
 %-Minimizes branching factor; Tries to cut off search ASAP

%\textbf{Most \emph{Constraining} Var Heur}
%-Tie-breaker among most-constrained vars
 %-Choose var with the most constraints on the remaining variables
 %-Called the \textbf{degree heuristic}(reduces the branching factor on future choices by selecting varible involved in largest \# of constraints on other unassigned vars, tries to cut off search ASAP

%\textbf{Least Const Var Heur}
%-Variable that rules out the fewest vals in remaining vars
 %-try to pick values \emph{best} first
%\textbf{Min-Conflicts Heur}
 %-choose value that violates fewest constraints, i.e., hill-climb by minimizing f(n) = total \# of violated constraints
\subsection{*Min-Conflicts Algo}
\begin{verbatim}
1. Assign to each variable a random value, defining the 
initial state
2. while state not consistent do
 2.1 Pick a variable, var, that has constraint(s) violated
 2.2 Find value, v, for var that minimizes the total number 
 of violated constraints (over all variables)
 2.3 var = v
\end{verbatim}

-Advantages:
Simple and Fast: Given rand init state, can solve n-queens in almost O(1)

-Disadvantages:

\quad -Only searches states that are reachable from the init state(May not search entire state space)

\quad -Does not allow worse moves (but can move to neighbor w/ same cost; can get stuck at loc optimum)

\quad -Not complete, may not find a soln 

\subsection{*Forward Checking Algorithm}
-For each var, record the \textbf{set of all possible legal values for it}

-When val assign to var in search, update set of legal vals for \textbf{all} unassigned vars.  Backtrack immediately if you \textbf{empty} a variable's set of possible values

-Keep track of \textbf{remaining legal values} for all variables

-Deadend when any var has \textbf{no} legal values

-propagates info from assigned to unassigned vars; doesn't provide early detection for all failures

\textbf{-Constraint propagation} recursively enforces constraints for all vars. \textbf{Main idea:} if value deleted from var's domain, check all vars connected to \emph{it}. If any change,, delete all inconsistent values connected to them, etc.

\subsection{*Arc Consistency Algo(AC-3)}

\textbf{Arc Consistency}: Simplest form of propagation makes each \textbf{arc consistent}

{\scriptsize
- $X\to Y$ is consistent \textbf{if} for \textbf{every} value x at var X there is \textbf{some} allowed y, i.e. there is at least 1 value of Y t.s. consistent with x at X, \textbf{if not, delete x}
}

\includegraphics[width=1.5in,height=1in,keepaspectratio]{ac_3_algorithm.png}
\includegraphics[width=1.5in,height=1in,keepaspectratio]{Revise.PNG}

\subsection{*Combining Search w/ CSP Inference}

{\scriptsize
\textbf{-Idea:} Interleave search and CSP inference

\textbf{-Perform DFS}: At each node, assign a selected value to a selected var, \textbf{then} run CSP to reduce vars' domains and check if any inconsistencies arise as a result of this assignment
}
\includegraphics[width=2.5in,height=1.2in]{combosearch.PNG}

%------------------------------------------------------------

\section{**Support Vector Machines}

-Used for Classification, Regression and data-fitting, and Supervised/unsupervised learning

-Can only handle two-class problems

-\emph{k-class problem:} split task into k \textbf{binary} tasks and learn k SVMs
%Maximum margin, defn of margin, kernel trick, support vectors, slack variables

\subsection{*Maximum Margin}

\textbf{-Margin}: distance from center dec line to nearest data point, \textbf{max margin} is a dec boundary w/ largest possible dist

-Computed w/ + plane = $\textbf{w}^T\textbf{x} + b = +1$(- plane same but `= -1')



\subsection{*Slack Variables}

-For Non-LSVMs, one option is to allow a few points on the wrong side (slack vars) $\to$ ``Soft Margin Classification''

-How? $\to Minimize, ||\textbf{w}^2|| + C(\# trainerrors)$(C is tradeoff ``penalty'' param), solving may be slow since it can't be expressed as a quad programming prob

-\textbf{C} needs a good val cause, if it's too big, similar to LSVM \& could \textbf{overfit}, if too small, allows many misclassifications \& may \textbf{underfit}. \textbf{Optimization criterion?} $\to Minimize \frac{1}{2} \textbf{w}^T + C\sum_{k=1}^{N}\varepsilon_k$, where $\varepsilon_k$ is the $k^th$ slack variable dist to the correct dec boundary margin, and N is \# constraints($\varepsilon_k = 0$ for correct zone)

-$\textbf{w}^T\textbf{x} + b \ge 1 - \varepsilon_k if y_k = +1 \& \textbf{w}^T\textbf{x} + b \le -1 + \varepsilon_k if y_k = -1$

\subsection{*Kernel Trick}

-Other option for Non-LSVMs, Maps data to a higher dimensional space, \& then do linear classification

-\textbf{Example:} $\Phi(x) = (x, x^2)$ 1D $\to$ 2D

-Also, use $\textbf{w}^T\Phi(\textbf{x}) + b = \pm1$

-For 2D $\to$ 3D: $\Phi(x_1,x_2) = (x_1,x_2,\sqrt{x_1^2 + x_2^2})$

\begin{tabbing}
-Common Kernels: \= \textbf{Linear}: $K(\textbf{x}_i,\textbf{x}_j) = \textbf{x}_i^T\textbf{x}_j$\\

\>\textbf{Quadratic}: $K(\textbf{x}_i,\textbf{x}_j) = (\textbf{x}_i^T\textbf{x}_j + 1)^2$\\
\end{tabbing}
%-------------------------------------------------------------
\section{**Neural Networks}
   
\textbf{Activation function}: Computes an output scalar val using simple non linear func of the linear combo of its inputs

\textbf{LTU}: Activation flips from 0 to 1 when activation func $\ge$ threshold $b$

-Given n inputs, a unit's \textbf{activation}(output) is $g(in) = g(\sum_{i=1}^{n} w_i x_i)$

%\newpage
\textbf{Sigmoid Function}: $\frac{1}{1+e^-x}$, Derivative: $g'(x) = g(x)(1-g(x))$

-slow learning because ``saturated'' units ``kill'' gradients

\textbf{ReLU}: $g(z) = max(0,z)$, $g'(z) = \begin{cases} 0, & if z \le 0\\1, & otherwise\end{cases}$

-Reaches 25\% error rate 6x faster than sigmoid

\textbf{Softmax}: $g(z_j) = \frac{e^{z_j}}{\sum_{k=1}^{K}e^{z_k}}$i

-All output units sum to 1, i.e., [3,1,1] $\to$ [.78,.11,.11]
%Perceptron, LTU, activation functions, bias input, input units, output units, Perceptron learning rule, Perceptron learning algorithm, Perceptron convergence thm, epoch, weight space, input space, linearly separable, credit assignment problem, multi-layer feed-forward networks, hidden units, sigmoid func, ReLU, softmax, back-prop algo, gradient descent search in weight space, stochastic gradient descent, parameter setting using a tuning set, deep learning, convolutional neural networks, pooling

\subsection{*Perceptron}

\textbf{``1-layer network''}: one or more output units, Output units are all LTUs

\textbf{Perceptron Learning Rule}: $w_i = w_i + \Delta w_i$ where $\Delta w_i = \alpha x_i(T-O)$, where $x_i$ is input associated with $i^{th}$ input unit, $\alpha$ is the learning rate between 0.0-1.0

-Determining how to update the weights is an instance of the \textbf{credit assignment problem}, which is determining which weights to credit/blame for the output error in the network, and how to update them

-"local" learning rule; only local info in network needed to update $w$, performs \textbf{gradient descent (hill-climbing) in "weight space"}

-Can only learn funcs that are \textbf{linearly separable}(in \textbf{input space})

-\textbf{Algorithm}: \textbf{1.} Init network weights \textbf{2.} Repeat until all examples correctly classified/stopping criteria met(epochs)

\textbf{Perceptron Convergence Thm}: If a set of examples is learnable, PLR will find appropriate set of weights in 1. finite steps, 2. indep of init weights, 3. using sufficiently small $\alpha$ value

\subsection{*Multi-Layer, Feed-Forward Networks}

-Gotta solve the Credit Assingment Problem!

\begin{tabbing}
-Ba\=ck-Propogation: Method for learning weights in networks, \\
        generalizes PLR\\
\>-Approach $\to$ \textbf{Gradient-descent algo} to minimize total \\\>error on train set. \\
\>-Errors are propagated through the network starting at the \\\>output units and working backwards towards the input units
\end{tabbing}

\textbf{Back-Prop using Stochastic Gradient Descent}:

-\textbf{Back-Prop} performs a \textbf{gradient descent search} in ``weight space'' to learn network weights

-\textbf{Updating Weights}

-Given a network w/ n weights: \textbf{-}each config of weights is a vector, \textbf{W}, of length n that defines an instance of the network. \textbf{-W} can be considered a pt in a n-D \textbf{weight space}, where each dimension is associated w/ 1 of the connections in the network

-Given a train set of m exmpls: \textbf{-}Each net defn by vector \textbf{W} has an associated total error, \textbf{E}, on all train data E(Sum squared error) = $\sum_{i=1}^{m} E_i$, Given t output units, $E_i = \sum_{i=1}^{t} (T_i - O_i)^2$ 

\textbf{For 2-Layer}

-\textbf{H-O Weights}: $\Delta w_{j,k} = \alpha a_j \Delta_k$, $\Delta_k=(Err_k)(g'(in_k)$,$\alpha_j$=output 

-\textbf{I-H Weights}: $\Delta w_{i,j} = \alpha a_i \Delta_j$, $\Delta_j=g'(in_j)\sum_{k}w_{j,k}\Delta_k$

\textbf{Back-Prop Algo}

\includegraphics[width=3in,height=1.3in]{backprop.PNG}

{\scriptsize
-Issues With Back-Prop: Requires labeled train data(almost all data unlabeled), Learning time doesn't scale well(very slow to converge in networks w/ multiple hidden layers), might get stuck at poor local optimum, overfitting
}

\subsection{*Param Setting W/ Tune Set}

-Use a tuning set(validation set) to train using several andidate values for $\alpha$, and select val that gives lower err

-Train network until err rate on a \textbf{tuning set} begins increasing rather than training until err on train is minimized

-How many hidden units in a layer? Too few, concept can't be learned. Too many, examples memorized/overfitting

\textbf{Dropout}: To prevent overfit, during train, at each hidden layer, ``drop out'' a rand set of units from that layer by setting outputs to 0 in forward pass

-Each unit is retained with prob p = 0.5

-Back-prop is performed only on thinned network

-During testing, use whole net(weights must all be rescaled)

\subsection{*Deep Learning}

-Use many hidden layers(often 10-20)

-Automatically learns features from the raw data

-\textbf{Issues Training Deep Networks}: Bottom layers don't get trained easily, small data sets result in not enough labeled data for training, use a pre-processing step to init weights, use traditional back-prop to train full net

\subsection{*Convolutional Neural Networks}

-Extension of multi-layer, feed-forward nets that incorporate the following: Use of \textbf{many layers}(learn a hierarchy of features), \textbf{Local "receptive fields"/filters and local connections}(Layers aren't completely connected, Want translation-invariant local features), \textbf{Shared weights, Pooling}

\textbf{Convolution Operation}: $h[m,n] = \sum_{k,l}g[k,l]f[m-k,n-l]$(replace - with + for image filtering)

-\textbf{In CNN's, $f$ corresponds to the inputs from the layer below and $g$ corresponds to the weights}

\textbf{Convolution Layers}: Learn ``filters''(weights) that process small regions of the layer below it an compute ``features'' at many spatial positions

-\textbf{Ex:} 32x32x3 image w/ 5x5 filter.  Each unit will have weights connected to a 5x5x3 region in input layer(75 weights)

\begin{tabbing}
ReL\=U Layers\\
\>-Each Conv layer usually followed by ReLU layer, applies ReLU \\\>func to conv layer output\\
\>-No weights to be learned\\
\>-Layer size = to size of layer below it\\
\end{tabbing}

\textbf{Pooling Layers}: Follows ReLU layer.  Gets a small amount of translational invariance \& robustness to noise by combining  neighboring values to give a single output at the next layer. \textbf{Max Pooling}: Combine by taking max, \textbf{Avg Pooling}, \textbf{Sub-Sampling}: Reduces size of next layer according to size of pooling filter. \textbf{ex:}a 2x2 filter reduces size by $\frac{1}{2}$ in each dimension

\section{**Reasoning under Uncertainty}

\textbf{Random Variable}: A var, X, whose domain is a sample space, w/ somewhat uncertain val.  \textbf{Ex:} X = coin flip outcome \textbf{Mutually Exclusive:} discrete number of outcome. \textbf{Prior Prob}: a single probability(P(A=a) or P(a))

\textbf{3 Axioms of probability}: \textbf{1.} $0 \le P(A) \le 1$ \textbf{2.} $P(true)=1,P(false)=0$ \textbf{3.} $P(A\lor B)=P(A)+P(B) - P(A\land B)$

Thms derived from Axioms: $P(\neg A)=1-P(A), P(B)=\sum_{i=1...k}P(B,A=a_i)$

\textbf{Joint Probability}: P(A=a, B=b), shorthand $P(A=a\land B=b)$

\textbf{Conditional Prob}: $P(a | e)$: Specifies belief in a proposition that is conditioned on a proposition being true. Behaves the same
\textbf{-With Mult Evidence}: $P(\neg B|F, \neg Y)=P(\neg B, F, \neg Y) / P(F,\neg Y)$

\textbf{Prior Prob}: prior to having any data about an event/other events. 
\textbf{Marginal Probs}: summing over all other variables.(i.e., \textbf{Summing out})
\textbf{Posterior Prob}: Prob of A after knowing evidence B (i.e., $P(A|B)$)


\subsection{Important Rules}
\begin{tabular}{ll}
Conditional Probability&$P(A|B)=\frac{P(A,B)}{P(B)}$\\
Product Rule&$P(A,B)=P(A|B)P(B)$\\
Chain Rule&$P(A,B,C,D)=P(A|B,C,D)$\\&$P(B|C,D)P(C|D)P(D)$\\
Cond V. of Chain Rule&$P(A,B|C)=P(A|B,C)P(B|C)$\\
Bayes's Rule&$P(A|B)=\frac{P(B|A)P(A)}{P(B))}$\\
Cond V. of Bayes's&$P(A|B,C)=\frac{P(B|A,C)P(A|C)}{P(B|C)}$\\
Addition/Conditioning rule&$P(A)=P(A,B)+P(A,\neg B)$\\&\tiny{$P(A)=P(A|B)P(B)+P(A|\neg B)P(\neg B)$}\\
\end{tabular}

\textbf{Normalization}: using a normalization constant for distribution(i.e., $P(\neg B|F)+P(B|F)=1$)
\textbf{Degrees of Freedom}: \# of independent values
\textbf{Independence}: 2 events A,B independent if one of following hold, P(A,B)=P(A)P(B)...$P(A|B)=P(A)...$

\textbf{Conditional Independence}: ``A \& B are cond indep given C'' means: $P(A|B,C)=P(A|C), P(B|A,C)=P(B|C), P(A,B|C)=P(A|C)P(B|C)$

\textbf{Naive Bayes Classifier}: $argmax_cP(Y=c)\prod_{i=1}^nP(X_i=v_i)|Y=c)$

-Assume all values conditionally indep

-Cond probs can be small, to avoid underflow, use $argmax_c logP(Y=c)+\sum_{i=1}^nlogP(X_i=v_i|Y=c)$

\textbf{Add-1 Smoothing}: Train data may not include some cases, this ensures every cond prob >0 by pretending you see each attr val 1 extra time,

$P(X=v_i|Y=c)=\frac{count(X=v_i,Y=c)+1}{count(Y=c)+m}$



\textbf{Lapace Smoothing}: instead of adding 1, add a + real \#, $\delta$
%Random variable, mutually exclusive, prior probability, 3 axioms of probability, joint probability, conditional probability, posterior probabililty, full joint probability distro, degrees of freedom, summing out, marginalization, normalization, product rule, chain rule, conditionalized version of summing out, marginalization, normalization, product rule, chain rule, Baye's rule, conditionalized version of Bayes's rule, addition/conditioning rule, independence, conditional independence, naive Bayes classifier, add-1 smoothing, Laplace smoothing.

\section{**Bayesian Networks} 

-Allow us to represent joint distros in manageable chucks using Indep \& Cond Indep
\subsection{*Bayesian Network Directed Acrylic Graphs}
-Nodes=random vars, cond prob tables(CPTs) stored at each node quantifies cond prob of node's

\textbf{Deductive} influence of directed graph $A\to B$ means evidence for A increases liikelihood of B, ev for B increases liklihood of A for \textbf{abductive}

\textbf{Cond Indep in BNs}: A node is cond indep of its non-descendants, given its parents, also CI of all other nodes given parents, children, and children's parents.  $A\to C \leftarrow B$: A and B are indep given nothing else, dependent given C.

\textbf{Inference By Enum}:

Algorithm: $P(E_1|E_2)=\frac{P(E_1\land E_2)}{P(E_2)}=\frac{\sum_{joint entries matching E_1 and E_2}P(joint entry)}{\sum_{joint entries matching E_2}P(joint entry)}$

There are $k^{N-j}$ joints to sum, k=number of values per var, N=numVars, j=evidence vars, but can compute any cond prob

\textbf{Smoothing CPTs}: Ex)$P(A|B,E)$=[\#(A)+1 + \#$(\neg A)+1$], Saves you when you don't have enough data, hides when you do.
-For Naive Bayes: $P(V_i|c)=\frac{n_{ci}+1}{n_c+k}$, $n_{ci}$=\# timestoken type $v_i$ occurs, $n_c$=total \# of tokens in all examples of class c
%Bayesian network DAG, conditional probability tables, space saving compared to full joint prob distro table, conditional independence property defined by a Bayesian network, inference by enumeration from a Bayesian network, naive Bayes classifier, add-1 smoothing, Laplace smoothing



\section{**Speech Recognition}

-Mapping acoustic signal into a string of words

\textbf{Phones}: Distinct sounds in the human language.(Characterized in terms of acoustic features, e.g., frequency and amplitude) \textbf{Phonemes}: equivalence classes of phones that cant be distinguished from each other

\textbf{Applying Bayes}: $P(Words|Signal)=P(Signal|Words)P(Words)/P(Signal)$

P(Words): \textbf{Language Model} $\to$ Likelihood of words being heard, e.g., "recognize speech"

-Joint Prob that a seq of Words is likely for specified language(chain rule). \textbf{Bigram}: only depends on prev word, \textbf{Trigram}:two prev words

-\textbf{First-order Markov Assumption}: Prob of a word only depends on prev word(bigram model). Probabilities stored in a \textbf{Probabilistic finite state machine}: Almost fully connected directed graph, Nodes are all possible words and a START state, arcs labeled w/ probability from START to a word is the prior prob of dest word being first word. CP after first word.

$P(Signal|Words)$: \textbf{Acoustic Model}: liklihood of sig given word seq, accounts for diff pronunciations.

-\textbf{Two Probabilities}: $P(Phones|Word)$(Markov Model), $P(Signal|Phones)$(Hidden Markov Model)

\textbf{$1_{st}$-order Markov Model}:Assumption: State $q_{t+1}$ is CI of other states given $q_t$. -Discrete set of states, $s_1,s_2,...,s_N$ \textbf{$\pi$ Vector}: \textbf{$\pi_i$} = $P(q_1=s_i)$ Prior probabilities of the init state at time t=0. \textbf{State Trans Matrix}:\textbf{A}=$(a_{ij})$, where $a_{ij}$=$P(q_{t+1}=s_j|q_t=s_i)$ Helps move markov process from state-to-state, graph of probabilities.

\textbf{HMMs}: -Hidden States: Represented as 1st order MM, states of real interest. -Observable States: related to HSs

-\textbf{Observation Likelihood Matrix}(Output Prob Distro):Stores probabilities associated w/arcs from hidden to observable states($P(Observed|Hidden)$).

-An HMM, $\lambda$ = \textbf{A, B, $\pi$}, contains 3 sets of probs

-\textbf{$\pi$} vector, \textbf{$\pi$}=($\pi_i$), -State trans matrix, \textbf{A}=($a_{ij}$), where $a_{ij}=P(q_t=s_i|q_{t-1}=s_j)$, Observation liklihood Matrix, \textbf{B}=$b_j(o_k)=P(y_t=o_k|q_t=s_j)$, o=observable s=hidden

%Phones, phonemes, speech recog using Bayes's rule, language model, acoustic model, bigram model, trigram model, first-order Markov assumption, probabilistic finit state machine, first-order Markov model, state transition matrix, pi vector, computing conditional probabilities from a Markov model, hidden Markov model, observation likelihood matrix, computing joint probabilities and conditional probabilities from an HMM by enumeration.  (Nothing ond Forward algo, Viterbi algo, Forward-Backward algo, Siri, particle filters, tracking in video.)



\section{**Computer Vision}

\textbf{Viola-Jones Algorithm}: -Compute lots of simple features, -Efficiently choose best features, -Each feature is used to define a "Weak Classifier"("aka decision stump"), -Combine weak classifiers into an ensemble classifier(EC) based on boosting(Adaboost), -Learn mult ECs and ``cascade'' them together to improve classification accuracy and speed

\textbf{Decision Stump}: acts as a Dec Tree w/ a root node, containing the test $h_t(x)$, and 2 leaft nodes below
%Viola-Jones face detection algo, boosting ensemble learning, AdaBoost algo, weak classifier, weighted-majority classification, decision stump.



\newpage

\section{Resources}
Great symbol look-up site: \href{http://detexify.kirelabs.org/}{Detexify}\\
\href{http://amath.colorado.edu/documentation/LaTeX/Symbols.pdf}{\LaTeX\ Mathematical Symbols}\\
\href{ftp://tug.ctan.org/pub/tex-archive/info/symbols/comprehensive/symbols-letter.pdf}{The Comprehensive \LaTeX\ Symbol List}\\ 
\href{http://mirrors.med.harvard.edu/ctan/info/lshort/english/lshort.pdf}{The Not So Short Introduction to \LaTeX\ 2$\varepsilon$}\\
\href{http://www.tug.org/}{TUG: The \TeX\ Users Group}\\
\href{http://www.ctan.org/}{CTAN: The Comprehensive \TeX\ Archive Network}\\
~\\
\LaTeX\ for the Mac: \href{http://www.tug.org/mactex/}{Mac\TeX}\\
\LaTeX\ for the PC: \href{http://www.texniccenter.org/}{{\TeX}nicCenter} and \href{http://miktex.org/}{MiK\TeX}\\
\LaTeX\ online: \href{http://www.writelatex.com/}{WriteLaTeX}.
\vfill
\hrule
~\\
Jack Farrell, jfarrell3@wisc.edu
\end{multicols}

\end{document}
